# Edge
How to Develop and Deploy an AI-Powered Object Detection Service on a Raspberry Pi Cluster using Python and YOLOv8

In this guide, you will learn how to create and deploy an API serverless endpoint web service for object detection using Python and the official YOLOv8 library based on PyTorch on a cluster of Raspberry Pi devices using OpenFaaS and ONNX, a lightweight runtime created by Microsoft.

Prerequisites
- A cluster of Raspberry Pi devices configured with Debian GNU/Linux. You can follow this tutorial: https://rpi4cluster.com/k3s/k3s-hardware/ to set up your cluster from scratch.
- How to create YOLOv8-based object detection web service using Python
- Basic knowledge of Python and OpenFaaS.
Overview
The steps involved in this project are:
1. Install and configure the necessary tools on the cluster, such as OpenFaaS, faas-cli, and Docker.
2. Create a Python function using the python3-http-debian template from OpenFaaS. This template will allow us to use any Python dependencies and libraries without compatibility issues.
3. Write the code for the object detection service using the YOLOv8 library and the ONNX runtime. We will work with the Yolov8 model on the low-level, without relying on PyTorch or the official API.
4. Build and deploy the function on the cluster using the faas-cli and the .yml file generated by the template.
5. Test and invoke the function using the OpenFaaS web UI or the curl command.

Detailed Steps
1. Install and configure the necessary tools on the cluster

    - Follow the steps from this chapter: https://rpi4cluster.com/k3s/k3s-nodes-setting/ of the rpi4cluster tutorial to install and configure OpenFaaS, faas-cli, and Docker on your cluster. You can skip the rest of the steps after Openfaas First Function chapter as we will not use it for this project.

2. Create a Python function using the python3-http-debian template from OpenFaaS

    - On your laptop or computer, open a terminal and navigate to the directory where you want to create your function.
    - Run the following command to download templates to your directory where you will be creating functions and then create a new function using the python3-http-debian template:

    ```
    cd /path/to/working/directory
    faas-cli template pull
    faas-cli new --lang python3-http-debian your-function-name
    ```

    - This will create a new directory with the same name as your function and a .yml file with the same name. The directory will contain three files: handler.py, requirements.txt, and Dockerfile. The .yml file will contain the configuration for your function, such as the image name, the environment variables, and the secrets.


Developing an AI-Powered Object Detection Service on a Local Raspberry Pi Cluster using Python:
Recommended reading:
https://rpi4cluster.com/k3s/k3s-hardware/
How to create YOLOv8-based object detection web service using Python

In this guide, I will walk you through the process of creating a web service for object detection using Python and the official YOLOv8 library based on PyTorch. Our focus will be on the low-level workings of the YOLOv8 model, bypassing the need for PyTorch or the official API. The backend deployment options will be explored, emphasizing the use of ONNX, a lightweight runtime created by Microsoft. The following steps in this blog assume you already have a cluster of raspberry pi‚Äôs configured with Debian GNU/Linux. I recommend reading and walking through the website: https://rpi4cluster.com/k3s/k3s-hardware/ if you do not have this cluster set up yet. I was generously given a cluster of 5 raspberry pi‚Äôs by my professor, Arun Ravindran, which saved me the time of flashing, installing, and configuring the OS on each raspberry pi, for which I am very grateful.
Once I received this pre-booted up raspberry pi cluster, I connected each raspberry pi node to my local area network via Wifi and connected to each node via SSH from my laptop in order to have a more comfortable working environment, so I did not have to always be next to the cluster with a monitor, mouse and keyboard connected to it. Once we have access to every node from my laptop via SSH, we‚Äôre in business! You can start following the steps from this chapter on the website: ‚Äúhttps://rpi4cluster.com/k3s/k3s-nodes-setting/‚Äù and begin configuring your cluster with the necessary tools for this project. Please note that you do not have to connect to the cluster via SSH from your personal computer, but as I said before, I found it more comfortable doing it that way.
The last necessary chapter from the rpi4cluster website will be the openfaas first function. We won‚Äôt follow the exact steps on that last required chapter, as they create an emailing function, but it holds very important information about how to create, deploy and invoke your openfaas function on the raspberry pi cluster. Everything after that, including Redis, will not be necessary for this project, although it could provide helpful insights into your cluster‚Äôs performance.
Once you have all of that set up, I recommend reading the article:How to create YOLOv8-based object detection web service using Python, in order to get the background information necessary to know what we will be building with this python code.
This blog will essentially be a blend of the openfaas-first-function chapter of the rpi4cluster website and the dev.to blog, with slight adjustments to the beginning of the dev.to blog and the ‚Äúcreate a webservice on python‚Äù section of it, as well since we will be pulling a python template on openfaas instead of a standalone python file being executed and continuously running. Following the instructions of the rpi4cluster first-openfaas-function, we will pull a slightly different version of the python template, which will be the python-http-debian template, in order to avoid any potential issues you might get from when the dockerfile installs any requirements, to make sure they are compatible with my setup, since I am running a Debian/GNU Linux distro. Pulling this template using the command:
faas-cli new --lang python3-http-debian ‚Äúyour-function-name‚Äù
Creates a new directory with the same name as your-function-name and a .yml file of the same name as well. We will use this .yml file later to build our function, once we have the correct handle logic and required dependencies. Change the directory to your-function-name directory that was just created using the command:
cd your-function-name

Back End Deployment Options:
To deploy YOLOv8 models, originally created using PyTorch and exported as .pt files, the Ultralytics API was traditionally employed. However, for production in k3s cluster, all that's needed is to run the model with an input image and receive the resulting bounding boxes. Ultralytics API's export function proves valuable, converting any YOLOv8 model to a format usable by external applications. One such format is ONNX, which serves as a universal platform for running neural networks.
Make sure you have Ultralytics installed on your laptop or computer using pip:
pip install ultralytics

Export YOLOv8 Model to ONNX:
Exporting the YOLOv8 model to ONNX format involves loading the model and executing a Python script. Using Ultralytics, this process is streamlined with a few lines of code, resulting in an ONNX file ready for deployment. Lets create a file using the command:
nano export_yolov8.py
Fill it with the following contents:
from ultralytics import YOLO

def main():
    model = YOLO("yolov8m.pt")
    model.export(format="onnx")

if __name__ == "__main__":
    main()
In this file we load the middle-sized YOLOv8 model for object detection and export it to the ONNX format
The model is pretrained on COCO dataset and can detect 80 object classes. On Mac, Press Control^ + X to exit, Y to save
You will want to execute this using the following command:
python export_yolov8.py
It will result in something like this:
Ultralytics YOLOv8.0.212 üöÄ Python-3.9.2 torch-2.1.1 CPU (Cortex-A72)
YOLOv8m summary (fused): 218 layers, 25886080 parameters, 0 gradients, 78.9 GFLOPs

PyTorch: starting from 'yolov8m.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (49.7 MB)

ONNX: starting export with onnx 1.15.0 opset 17...
ONNX: export success ‚úÖ 18.6s, saved as 'yolov8m.onnx' (99.0 MB)

Export complete (43.1s)
Results saved to /root/openfaas_scripts/yoloedge-debian
Predict:         yolo predict task=detect model=yolov8m.onnx imgsz=640
Validate:        yolo val task=detect model=yolov8m.onnx imgsz=640 data=coco.yaml
Visualize:       https://netron.app
root@master2:~/openfaas_scripts/yoloedge-debian# ls
export_yolov8.py  handler.py.save  requirements.txt  yolov8m.onnx
handler.py	  handler_test.py  tox.ini	     yolov8m.pt
The new files created from executing this python script are in bold and underlined. It downloads the .pt model if it does not find it in the current directory already, then exports it in onnx format to be used by our API serverless endpoint.

Next, copy and paste this code into the handler function, to find out what each def function besides the handle does, you can check the How to create a Yolov8-based object detection web service using Python article.

For the handle def function each line represents:
import onnxruntime as ort: This line imports the onnxruntime library and assigns it an alias ort. onnxruntime is a Python library used for inference with ONNX (Open Neural Network Exchange) models.
from PIL import Image: This line imports the Image module from the Python Imaging Library (PIL). PIL is a library used for opening, manipulating, and saving many different image file formats.
import numpy as np: This line imports the numpy library and assigns it an alias np. numpy is a powerful library for numerical computing in Python, especially for handling arrays and matrices.
import json: This line imports the built-in json module, which provides functions for encoding and decoding JSON data.
import io: This line imports the built-in io module, which provides functions for working with streams of data.
onnx_model_path = "function/yolov8m.onnx": This line defines the path to the ONNX model file (yolov8m.onnx). It assumes that the ONNX model file is located in the function directory.
model = ort.InferenceSession(onnx_model_path): This line creates an instance of the ONNX model using the InferenceSession class from onnxruntime. It loads the ONNX model from the specified path.
def handle(event, context):: This line defines a function named handle that takes two parameters: event and context. This function is likely the entry point for handling incoming requests, as it is common in serverless functions.
print("Handle function called"): This line prints a message indicating that the handle function has been called.
req = event.body: This line retrieves the request body from the event parameter. The event parameter likely contains information about the incoming HTTP request, and body is a property that represents the body of the request.
buf = io.BytesIO(req): This line creates a BytesIO object named buf from the request body. BytesIO is a class in the io module that provides a binary stream interface.
print("Buffer size:", len(buf.getvalue())): This line prints the size of the buffer (buf) by calling the getvalue() method, which returns the entire contents of the buffer as a bytes object.
boxes = detect_objects_on_image(buf): This line calls a function named detect_objects_on_image, passing the buf object as an argument. This function likely performs object detection using the ONNX model.
result = '\n'.join(json.dumps(box) for box in boxes): This line converts each detected box into a JSON string and joins them with newline characters. The json.dumps() function converts a Python object (in this case, each box) into a JSON string.
print("Result:", result): This line prints the result, which is a JSON string representing the detected boxes.
return {...}: This line returns a dictionary containing the response data. It likely includes a status code, response body (containing the detected boxes), and headers indicating the content type.
Once we have the handler.py function down, we can go ahead and type in our dependencies on the requirements.txt file. For this project, we will require only 3 which are:
onnxruntime
pillow
numpy
Copy and paste these three onto the requirements.txt file in order to install required dependencies for our handler.py function.
Once we have that information, we can go ahead and build, deploy, and invoke our openfaas function in order to have this yolov8-based object detection algorithm running on the Edge!
I would recommend following the ‚ÄúOpenFaaS First Function‚Äù Chapter from the rpi4cluster.com website for guidance. You will first build and push your openfaas function using the following command:
faas-cli publish -f ‚Äúyour-function-name‚Äù.yml --platforms linux/arm64
If you receive an error message, continue following the rpi4cluster article, it has steps to overcome an error message typical of receiving after building this function, which is using the buildx solution
If all goes well right after the publish command you should receive something similar to the following:
#25 pushing layers
#25 pushing layers 4.7s done
#25 pushing manifest for registry.cube.local:5000/‚Äúyour-function-name‚Äù:latest
#25 pushing manifest for registry.cube.local:5000/‚Äúyour-function-name‚Äù:latest 0.1s done
#25 DONE 18.1s
Image: registry.cube.local:5000/‚Äùyour-function-name‚Äù:latest built.
[0] < Building ‚Äúyour-function-name‚Äù done in 57.37s.
[0] Worker done.

Total build time: 57.37s
Up next, deploy the function on your kubernetes server:
faas-cli deploy -f mailme.yml
To send it an image and invoke it, you can use the following command:
curl -X POST --data-binary "@/path/to/source/file.jpg" openfaas.cube.local:8080/function/‚Äùyour-function-name‚Äù
And you should see similar results!:
root@master2:~/openfaas_scripts# curl -X POST --data-binary "@/root/giraffe.jpg" openfaas.cube.local:8080/function/yoloonedge
[165.67729711532593, 29.645538330078125, 448.03634881973267, 442.7772521972656, "giraffe", 0.9456049203872681]
[247.4454402923584, 204.80246543884277, 427.54154205322266, 444.31262016296387, "zebra", 0.9367939233779907]
If you encounter any issues with OpenFaaS, I recommend going through the rpi4cluster.com website for any troubleshooting needs.
Congratulations! You have successfully deployed an AI powered application on the edge!
Please check my github for all my source code: https://github.com/rubenmendoza1290/Edge.git

